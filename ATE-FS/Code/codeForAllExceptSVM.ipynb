{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9f2333",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-15T06:09:43.087728Z",
     "iopub.status.busy": "2024-02-15T06:09:43.087037Z",
     "iopub.status.idle": "2024-02-15T06:09:59.543936Z",
     "shell.execute_reply": "2024-02-15T06:09:59.542434Z"
    },
    "papermill": {
     "duration": 16.469528,
     "end_time": "2024-02-15T06:09:59.546940",
     "exception": false,
     "start_time": "2024-02-15T06:09:43.077412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (0.9.0)\r\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.24.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.11.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44f42c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:09:59.564188Z",
     "iopub.status.busy": "2024-02-15T06:09:59.563463Z",
     "iopub.status.idle": "2024-02-15T06:10:03.393866Z",
     "shell.execute_reply": "2024-02-15T06:10:03.392547Z"
    },
    "papermill": {
     "duration": 3.842149,
     "end_time": "2024-02-15T06:10:03.396794",
     "exception": false,
     "start_time": "2024-02-15T06:09:59.554645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from tabulate import tabulate\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef as mcc_score,  roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da648013",
   "metadata": {
    "papermill": {
     "duration": 0.006899,
     "end_time": "2024-02-15T06:10:03.411534",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.404635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9dc44e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.428424Z",
     "iopub.status.busy": "2024-02-15T06:10:03.427881Z",
     "iopub.status.idle": "2024-02-15T06:10:03.439356Z",
     "shell.execute_reply": "2024-02-15T06:10:03.437906Z"
    },
    "papermill": {
     "duration": 0.023337,
     "end_time": "2024-02-15T06:10:03.442197",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.418860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_aeeem_dataset(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df.rename(columns={df.columns[-1]: 'temp'}, inplace=True)\n",
    "    columns_to_drop = ['temp', 'classname', 'nonTrivialBugs', 'majorBugs', 'criticalBugs', 'highPriorityBugs']\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    df.loc[df['bugs'] > 0, 'bugs'] = 1\n",
    "    return df\n",
    "\n",
    "def process_jira_dataset(df):\n",
    "    columns_to_drop = ['File', 'RealBug', 'HeuBug', 'HeuBugCount']\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    df.loc[df['RealBugCount'] > 0, 'RealBugCount'] = 1\n",
    "    return df\n",
    "\n",
    "def process_promise_ck_dataset(df):\n",
    "    columns_to_drop = ['Name', 'version']\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=columns_to_drop)  \n",
    "    df.loc[df['bug'] > 0, 'bug'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08db9c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.458514Z",
     "iopub.status.busy": "2024-02-15T06:10:03.458112Z",
     "iopub.status.idle": "2024-02-15T06:10:03.466022Z",
     "shell.execute_reply": "2024-02-15T06:10:03.464534Z"
    },
    "papermill": {
     "duration": 0.019025,
     "end_time": "2024-02-15T06:10:03.468607",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.449582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_dataset(df, n):\n",
    "    num_features = df.shape[1]\n",
    "    normalized_df = pd.DataFrame(index=df.index, columns=df.columns, dtype=int)\n",
    "    for column in df.columns:\n",
    "        feature_values = df[column]\n",
    "        min_value = feature_values.min()\n",
    "        max_value = feature_values.max()\n",
    "        normalized_feature_values = np.round((feature_values - min_value) / (max_value - min_value) * (n - 1))\n",
    "        normalized_df[column] = normalized_feature_values\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04a6d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.484624Z",
     "iopub.status.busy": "2024-02-15T06:10:03.484242Z",
     "iopub.status.idle": "2024-02-15T06:10:03.495329Z",
     "shell.execute_reply": "2024-02-15T06:10:03.493997Z"
    },
    "papermill": {
     "duration": 0.021886,
     "end_time": "2024-02-15T06:10:03.497662",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.475776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_binary(df, num_bits):\n",
    "    def convert_to_binary_representation(column, num_bits):\n",
    "        return column.apply(lambda x: format(int(x), f'0{num_bits}b'))\n",
    "\n",
    "    binary_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for column in df.columns[:-1]:\n",
    "        binary_representation = convert_to_binary_representation(df[column], num_bits)\n",
    "        num_columns_needed = max(len(binary_representation.iloc[0]), num_bits)\n",
    "        \n",
    "        binary_columns = pd.DataFrame(binary_representation.apply(lambda x: pd.Series(list(x)).astype(int)))\n",
    "        binary_columns = binary_columns.iloc[:, :num_columns_needed]\n",
    "        \n",
    "        binary_columns.columns = [f'{column}_bit_{i}' for i in range(num_columns_needed)]\n",
    "        binary_df = pd.concat([binary_df, binary_columns], axis=1)\n",
    "    \n",
    "    binary_df = pd.concat([binary_df, df[df.columns[-1]]], axis=1)\n",
    "    return binary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c19adb",
   "metadata": {
    "papermill": {
     "duration": 0.006865,
     "end_time": "2024-02-15T06:10:03.511981",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.505116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884b2470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.528820Z",
     "iopub.status.busy": "2024-02-15T06:10:03.528333Z",
     "iopub.status.idle": "2024-02-15T06:10:03.542570Z",
     "shell.execute_reply": "2024-02-15T06:10:03.541362Z"
    },
    "papermill": {
     "duration": 0.025805,
     "end_time": "2024-02-15T06:10:03.545343",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.519538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ATE_learner(df, col_name):\n",
    "    X = df.drop(columns=[df.columns[-1]])\n",
    "    y = df[df.columns[-1]]\n",
    "    \n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    Xt1 = pd.DataFrame.copy(X)\n",
    "    Xt1[col_name] = 1\n",
    "    Xt0 = pd.DataFrame.copy(X)\n",
    "    Xt0[col_name] = 0\n",
    "    \n",
    "    ate_est = np.mean(model.predict(Xt1) - model.predict(Xt0))\n",
    "    return ate_est\n",
    "\n",
    "def ate_based_feature_learner(df, num_of_bits, num_of_feat):\n",
    "    norm_df = normalize_dataset(df, 1<<num_of_bits)\n",
    "    binary_df = convert_binary(norm_df, num_of_bits)\n",
    "    \n",
    "    norm_df.loc[norm_df[norm_df.columns[-1]] > 0, norm_df.columns[-1]] = 1\n",
    "    binary_df.loc[binary_df[binary_df.columns[-1]] > 0, binary_df.columns[-1]] = 1\n",
    "    \n",
    "    best_features = {}\n",
    "    num_columns = len(binary_df.columns)\n",
    "    for i in range(0, num_columns-1, num_of_bits):\n",
    "        total = 0\n",
    "        for j in range(0, num_of_bits):\n",
    "            total = total + get_ATE_learner(binary_df, binary_df.columns[i+j])\n",
    "        best_features[binary_df.columns[i]] = total\n",
    "    \n",
    "    sorted_features = sorted(best_features.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_k_features = [feat[0] for feat in sorted_features[:num_of_feat]]\n",
    "    top_best_features = [element.replace(\"_bit_0\", \"\") for element in top_k_features]\n",
    "    indices = [df.columns.get_loc(feat) for feat in top_best_features]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f320cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.562165Z",
     "iopub.status.busy": "2024-02-15T06:10:03.561407Z",
     "iopub.status.idle": "2024-02-15T06:10:03.567067Z",
     "shell.execute_reply": "2024-02-15T06:10:03.565570Z"
    },
    "papermill": {
     "duration": 0.016617,
     "end_time": "2024-02-15T06:10:03.569633",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.553016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_algo = {\n",
    "    'CFS-Learner': ate_based_feature_learner,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8b28c",
   "metadata": {
    "papermill": {
     "duration": 0.006705,
     "end_time": "2024-02-15T06:10:03.583581",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.576876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c050463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.600060Z",
     "iopub.status.busy": "2024-02-15T06:10:03.599581Z",
     "iopub.status.idle": "2024-02-15T06:10:03.612492Z",
     "shell.execute_reply": "2024-02-15T06:10:03.611253Z"
    },
    "papermill": {
     "duration": 0.023846,
     "end_time": "2024-02-15T06:10:03.614764",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.590918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_list = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"XgBoost\": XGBClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "#     \"SVM\":  svm.SVC(kernel='rbf')\n",
    "}\n",
    "models_search_params = {\n",
    "    \"KNN\": {  \n",
    "        'n_neighbors' : [3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31],\n",
    "        'weights' : ['uniform','distance'],\n",
    "        'metric' : ['minkowski','euclidean','manhattan']\n",
    "     },\n",
    "    \"Logistic Regression\": {\n",
    "        'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "        'C' : [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'solver' : ['lbfgs','newton-cg','liblinear', 'newton-cholesky', 'sag', 'saga'],\n",
    "        'max_iter' : [100, 1500, 3000]\n",
    "     },\n",
    "    \"Decision Tree\": {\n",
    "        'max_features': [1, 2, 3, 5, 7, 10, 'log2','sqrt', None],\n",
    "        'max_depth': [2, 3, 5, 7, 10, 20, 30, 40, 50, 60, 70, None],\n",
    "        'min_samples_split': [2, 3, 5, 7, 9, 10, 0.1, 0.2, 0.3],\n",
    "        'min_samples_leaf': [1, 2, 3, 5, 7, 9, 10, 0.1, 0.2],\n",
    "     },\n",
    "    \"Random Forest\": {\n",
    "        'max_depth': [2, 5, 10, None],\n",
    "        'max_features': ['log2', 'sqrt', None],\n",
    "    },\n",
    "    \"XgBoost\": {\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 6, 10],\n",
    "        'subsample': [0.5, 0.7, 1],\n",
    "        'n_estimators': [100, 500]\n",
    "    },\n",
    "}\n",
    "\n",
    "no_of_iter_for_cv = {\n",
    "    \"KNN\": 30,\n",
    "    \"Decision Tree\": 30,\n",
    "    \"Logistic Regression\": 15,\n",
    "    \"Random Forest\": 5,\n",
    "    \"XgBoost\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130928c",
   "metadata": {
    "papermill": {
     "duration": 0.00671,
     "end_time": "2024-02-15T06:10:03.628603",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.621893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81ef920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.644562Z",
     "iopub.status.busy": "2024-02-15T06:10:03.644114Z",
     "iopub.status.idle": "2024-02-15T06:10:03.653573Z",
     "shell.execute_reply": "2024-02-15T06:10:03.652342Z"
    },
    "papermill": {
     "duration": 0.020455,
     "end_time": "2024-02-15T06:10:03.656130",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.635675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def g_measure_score(y_test, y_pred):\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "    FPR = FP/(FP+TN)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    g_measure = (2*recall*(1-FPR))/(recall+(1-FPR))\n",
    "    return g_measure\n",
    "\n",
    "def bal_score(y_test, y_pred):\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    FPR = FP/(FP+TN)\n",
    "    PF = FPR\n",
    "    PD = recall\n",
    "    bal = 1 - (math.sqrt((1-PD)*(1-PD)+(0-PF)*(0-PF))/math.sqrt(2))\n",
    "    return bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa3d8fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.672547Z",
     "iopub.status.busy": "2024-02-15T06:10:03.671823Z",
     "iopub.status.idle": "2024-02-15T06:10:03.679382Z",
     "shell.execute_reply": "2024-02-15T06:10:03.677893Z"
    },
    "papermill": {
     "duration": 0.018833,
     "end_time": "2024-02-15T06:10:03.682159",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.663326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_model_params(X_train, y_train, model):\n",
    "    classifier = models_list[model]\n",
    "    cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_obj = RandomizedSearchCV(classifier, models_search_params[model], n_iter = no_of_iter_for_cv[model], cv = cv, scoring='roc_auc')\n",
    "    grid_obj.fit(X_train, y_train)\n",
    "    best_model_params = grid_obj.best_params_\n",
    "    return best_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b0270e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.698430Z",
     "iopub.status.busy": "2024-02-15T06:10:03.698004Z",
     "iopub.status.idle": "2024-02-15T06:10:03.718712Z",
     "shell.execute_reply": "2024-02-15T06:10:03.717401Z"
    },
    "papermill": {
     "duration": 0.032045,
     "end_time": "2024-02-15T06:10:03.721491",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.689446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(file_name, X, y, model, feat_algo, col_list, num_of_bits, num_of_feat):\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    mcc_scores = []\n",
    "    roc_auc_scores = []\n",
    "    g_measure_scores = []\n",
    "    bal_scores = []\n",
    "\n",
    "    best_model_params = {}\n",
    "    features = []\n",
    "    \n",
    "    kf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "       \n",
    "        adasyn = ADASYN()\n",
    "        X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "            \n",
    "        if feat_algo != 'None' and len(features)<1:\n",
    "            train_df = pd.concat([pd.DataFrame(X_train), pd.Series(y_train, name='bug')], axis=1)\n",
    "            train_df.columns = col_list\n",
    "            features = feature_algo[feat_algo](train_df, num_of_bits, num_of_feat)\n",
    "        \n",
    "        if len(features) >= 1 and feat_algo != 'None':\n",
    "            X_train = X_train[:, features]\n",
    "            X_test = X_test[:, features]\n",
    "        elif feat_algo != 'None':\n",
    "            return [file_name, feat_algo, '--', '--', '--', '--', '--', '--', '--']\n",
    "        \n",
    "        if not best_model_params:\n",
    "            best_model_params = get_best_model_params(X_train, y_train, model)\n",
    "            print(file_name, feat_algo, model, best_model_params)\n",
    "            \n",
    "        classifier = models_list[model]\n",
    "        classifier.set_params(**best_model_params)\n",
    "        \n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        \n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        mcc_scores.append(mcc_score(y_test, y_pred))\n",
    "        roc_auc_scores.append(roc_auc_score(y_test, classifier.predict_proba(X_test)[:, 1]))\n",
    "        g_measure_scores.append(g_measure_score(y_test, y_pred))\n",
    "        bal_scores.append(bal_score(y_test, y_pred))\n",
    "    \n",
    "    return [file_name, feat_algo, num_of_bits, num_of_feat, round(np.mean(accuracy_scores),2), round(np.mean(precision_scores), 2), round(np.mean(recall_scores), 2), round(np.mean(f1_scores), 2), round(np.mean(mcc_scores), 2), round(np.mean(roc_auc_scores),2), round(np.mean(g_measure_scores), 2), round(np.mean(bal_scores), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0b2eb96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.738792Z",
     "iopub.status.busy": "2024-02-15T06:10:03.738348Z",
     "iopub.status.idle": "2024-02-15T06:10:03.744396Z",
     "shell.execute_reply": "2024-02-15T06:10:03.743159Z"
    },
    "papermill": {
     "duration": 0.017125,
     "end_time": "2024-02-15T06:10:03.746894",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.729769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_list_of_csv(folder_path):\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da51d02",
   "metadata": {
    "papermill": {
     "duration": 0.006796,
     "end_time": "2024-02-15T06:10:03.760849",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.754053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## JIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca259c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.777166Z",
     "iopub.status.busy": "2024-02-15T06:10:03.776696Z",
     "iopub.status.idle": "2024-02-15T06:10:03.787544Z",
     "shell.execute_reply": "2024-02-15T06:10:03.786315Z"
    },
    "papermill": {
     "duration": 0.022107,
     "end_time": "2024-02-15T06:10:03.790323",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.768216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_list = []\n",
    "folder_path = '/kaggle/input/defect-prediction/JIRA-defect-dataset/'\n",
    "\n",
    "for file_name in file_list:\n",
    "    \n",
    "    df = pd.read_csv(folder_path+file_name)\n",
    "    df = process_jira_dataset(df)\n",
    "    df = df.loc[:,df.apply(pd.Series.nunique) != 1]\n",
    "    \n",
    "    \n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "\n",
    "    for model in models_list.keys():\n",
    "        print('----------------', model ,'---------------------------')\n",
    "        table = []\n",
    "        table.append([\"dataset\", \"feat_algo\", \"no_of_bits\", \"no_of_feat\", \"acc\", \"prec\", \"recall\", \"f1\", \"mcc\", \"roc_auc\", \"g-m\", \"bal\"])\n",
    "\n",
    "        for num_of_bits in range(6, 15, 2): \n",
    "            num_of_feat = 6\n",
    "            for feat_algo in feature_algo.keys():\n",
    "                table.append(build_model(file_name, X, y, model, feat_algo, df.columns, num_of_bits, num_of_feat))\n",
    "            \n",
    "        print(tabulate(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c01e616",
   "metadata": {
    "papermill": {
     "duration": 0.006693,
     "end_time": "2024-02-15T06:10:03.804278",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.797585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TERA-PROMISE-CK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd23773c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T06:10:03.819966Z",
     "iopub.status.busy": "2024-02-15T06:10:03.819514Z",
     "iopub.status.idle": "2024-02-15T07:22:49.242607Z",
     "shell.execute_reply": "2024-02-15T07:22:49.238095Z"
    },
    "papermill": {
     "duration": 4365.435927,
     "end_time": "2024-02-15T07:22:49.247201",
     "exception": false,
     "start_time": "2024-02-15T06:10:03.811274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- KNN ---------------------------\n",
      "prop-5.csv CFS-Learner KNN {'weights': 'distance', 'n_neighbors': 13, 'metric': 'manhattan'}\n",
      "prop-5.csv CFS-Learner KNN {'weights': 'distance', 'n_neighbors': 29, 'metric': 'manhattan'}\n",
      "prop-5.csv CFS-Learner KNN {'weights': 'distance', 'n_neighbors': 13, 'metric': 'manhattan'}\n",
      "prop-5.csv CFS-Learner KNN {'weights': 'distance', 'n_neighbors': 23, 'metric': 'manhattan'}\n",
      "prop-5.csv CFS-Learner KNN {'weights': 'distance', 'n_neighbors': 15, 'metric': 'manhattan'}\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n",
      "dataset     feat_algo    no_of_bits  no_of_feat  acc   prec  recall  f1    mcc   roc_auc  g-m   bal\n",
      "prop-5.csv  CFS-Learner  6           6           0.81  0.59  0.57    0.57  0.15  0.67     0.7   0.69\n",
      "prop-5.csv  CFS-Learner  8           6           0.82  0.59  0.55    0.56  0.14  0.67     0.69  0.68\n",
      "prop-5.csv  CFS-Learner  10          6           0.75  0.56  0.58    0.57  0.14  0.62     0.68  0.68\n",
      "prop-5.csv  CFS-Learner  12          6           0.77  0.57  0.58    0.58  0.15  0.63     0.69  0.69\n",
      "prop-5.csv  CFS-Learner  14          6           0.8   0.59  0.57    0.57  0.15  0.67     0.7   0.69\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n",
      "---------------- Decision Tree ---------------------------\n",
      "prop-5.csv CFS-Learner Decision Tree {'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 10, 'max_depth': 60}\n",
      "prop-5.csv CFS-Learner Decision Tree {'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': 5, 'max_depth': 50}\n",
      "prop-5.csv CFS-Learner Decision Tree {'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 30}\n",
      "prop-5.csv CFS-Learner Decision Tree {'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 7, 'max_depth': None}\n",
      "prop-5.csv CFS-Learner Decision Tree {'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 5, 'max_depth': 70}\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n",
      "dataset     feat_algo    no_of_bits  no_of_feat  acc   prec  recall  f1    mcc   roc_auc  g-m   bal\n",
      "prop-5.csv  CFS-Learner  6           6           0.79  0.58  0.58    0.58  0.16  0.69     0.7   0.69\n",
      "prop-5.csv  CFS-Learner  8           6           0.79  0.59  0.59    0.59  0.18  0.7      0.71  0.7\n",
      "prop-5.csv  CFS-Learner  10          6           0.77  0.56  0.56    0.56  0.13  0.67     0.68  0.68\n",
      "prop-5.csv  CFS-Learner  12          6           0.77  0.57  0.58    0.57  0.14  0.68     0.69  0.68\n",
      "prop-5.csv  CFS-Learner  14          6           0.79  0.57  0.56    0.57  0.14  0.7      0.69  0.68\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n",
      "---------------- XgBoost ---------------------------\n",
      "prop-5.csv CFS-Learner XgBoost {'subsample': 0.5, 'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "prop-5.csv CFS-Learner XgBoost {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.2}\n",
      "prop-5.csv CFS-Learner XgBoost {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.2}\n",
      "prop-5.csv CFS-Learner XgBoost {'subsample': 0.5, 'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "prop-5.csv CFS-Learner XgBoost {'subsample': 0.5, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n",
      "dataset     feat_algo    no_of_bits  no_of_feat  acc   prec  recall  f1    mcc   roc_auc  g-m   bal\n",
      "prop-5.csv  CFS-Learner  6           6           0.8   0.6   0.58    0.59  0.18  0.73     0.71  0.7\n",
      "prop-5.csv  CFS-Learner  8           6           0.77  0.57  0.57    0.57  0.13  0.71     0.68  0.68\n",
      "prop-5.csv  CFS-Learner  10          6           0.77  0.56  0.56    0.56  0.12  0.7      0.68  0.67\n",
      "prop-5.csv  CFS-Learner  12          6           0.79  0.58  0.57    0.58  0.15  0.72     0.7   0.69\n",
      "prop-5.csv  CFS-Learner  14          6           0.8   0.59  0.59    0.59  0.18  0.74     0.71  0.7\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n",
      "---------------- Random Forest ---------------------------\n",
      "prop-5.csv CFS-Learner Random Forest {'max_features': None, 'max_depth': None}\n",
      "prop-5.csv CFS-Learner Random Forest {'max_features': None, 'max_depth': 10}\n",
      "prop-5.csv CFS-Learner Random Forest {'max_features': 'log2', 'max_depth': None}\n",
      "prop-5.csv CFS-Learner Random Forest {'max_features': 'sqrt', 'max_depth': None}\n",
      "prop-5.csv CFS-Learner Random Forest {'max_features': None, 'max_depth': None}\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n",
      "dataset     feat_algo    no_of_bits  no_of_feat  acc   prec  recall  f1    mcc   roc_auc  g-m   bal\n",
      "prop-5.csv  CFS-Learner  6           6           0.77  0.55  0.55    0.55  0.1   0.69     0.67  0.67\n",
      "prop-5.csv  CFS-Learner  8           6           0.76  0.61  0.65    0.62  0.25  0.74     0.72  0.72\n",
      "prop-5.csv  CFS-Learner  10          6           0.8   0.58  0.57    0.57  0.15  0.71     0.7   0.69\n",
      "prop-5.csv  CFS-Learner  12          6           0.77  0.56  0.56    0.56  0.12  0.7      0.68  0.67\n",
      "prop-5.csv  CFS-Learner  14          6           0.8   0.58  0.56    0.57  0.14  0.72     0.69  0.68\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n",
      "---------------- Logistic Regression ---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.66601978 0.67379049 0.67785257 0.67781534        nan        nan\n",
      " 0.6772969         nan        nan        nan 0.67782822 0.67870459\n",
      " 0.67849033        nan 0.66819589]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop-5.csv CFS-Learner Logistic Regression {'solver': 'sag', 'penalty': 'l2', 'max_iter': 1500, 'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.68051452 0.68041559 0.68039545        nan        nan\n",
      "        nan 0.66165228        nan 0.67869516 0.67904958 0.67802697\n",
      "        nan        nan 0.67905051]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop-5.csv CFS-Learner Logistic Regression {'solver': 'saga', 'penalty': 'l1', 'max_iter': 1500, 'C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.65757204 0.66676513        nan        nan        nan 0.66085471\n",
      "        nan        nan        nan        nan 0.67789736        nan\n",
      "        nan        nan 0.66084885]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop-5.csv CFS-Learner Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.65460615 0.68243317        nan 0.68244558        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.68554161\n",
      "        nan 0.67212679        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop-5.csv CFS-Learner Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 100, 'C': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.67864371        nan 0.67522768 0.67247277\n",
      "        nan        nan 0.67868    0.67869862 0.67861455        nan\n",
      " 0.67858762 0.67522885        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop-5.csv CFS-Learner Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 100, 'C': 0.1}\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n",
      "dataset     feat_algo    no_of_bits  no_of_feat  acc   prec  recall  f1    mcc   roc_auc  g-m   bal\n",
      "prop-5.csv  CFS-Learner  6           6           0.65  0.56  0.62    0.55  0.17  0.68     0.64  0.64\n",
      "prop-5.csv  CFS-Learner  8           6           0.65  0.57  0.62    0.55  0.18  0.68     0.64  0.64\n",
      "prop-5.csv  CFS-Learner  10          6           0.69  0.57  0.63    0.57  0.19  0.69     0.67  0.67\n",
      "prop-5.csv  CFS-Learner  12          6           0.65  0.58  0.65    0.56  0.22  0.7      0.65  0.65\n",
      "prop-5.csv  CFS-Learner  14          6           0.65  0.57  0.63    0.55  0.19  0.68     0.64  0.64\n",
      "----------  -----------  ----------  ----------  ----  ----  ------  ----  ----  -------  ----  ----\n"
     ]
    }
   ],
   "source": [
    "file_list = ['prop-5.csv']\n",
    "folder_path = '/kaggle/input/defect-prediction/TeraPromise-defect-dataset/ck/'\n",
    "\n",
    "for file_name in file_list:\n",
    "    \n",
    "    df = pd.read_csv(folder_path+file_name)\n",
    "    df = process_promise_ck_dataset(df)\n",
    "    df = df.loc[:,df.apply(pd.Series.nunique) != 1]\n",
    "    \n",
    "    \n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "\n",
    "    for model in models_list.keys():\n",
    "        print('----------------', model ,'---------------------------')\n",
    "        table = []\n",
    "        table.append([\"dataset\", \"feat_algo\", \"no_of_bits\", \"no_of_feat\", \"acc\", \"prec\", \"recall\", \"f1\", \"mcc\", \"roc_auc\", \"g-m\", \"bal\"])\n",
    "\n",
    "        for num_of_bits in range(6, 15, 2): \n",
    "            num_of_feat = 6\n",
    "            for feat_algo in feature_algo.keys():\n",
    "                table.append(build_model(file_name, X, y, model, feat_algo, df.columns, num_of_bits, num_of_feat))\n",
    "            \n",
    "        print(tabulate(table))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3568505,
     "sourceId": 6214172,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4390.189949,
   "end_time": "2024-02-15T07:22:50.021182",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-15T06:09:39.831233",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
