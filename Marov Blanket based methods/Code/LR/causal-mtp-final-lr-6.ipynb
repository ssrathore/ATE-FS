{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de877fec",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-31T00:42:52.305937Z",
     "iopub.status.busy": "2023-10-31T00:42:52.305043Z",
     "iopub.status.idle": "2023-10-31T00:43:02.558416Z",
     "shell.execute_reply": "2023-10-31T00:43:02.557676Z"
    },
    "papermill": {
     "duration": 10.262404,
     "end_time": "2023-10-31T00:43:02.560379",
     "exception": false,
     "start_time": "2023-10-31T00:42:52.297975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyCausalFS\r\n",
      "  Downloading pyCausalFS-0.23-py3-none-any.whl (300 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.9/300.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (0.9.0)\r\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (1.7.6)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.11.2)\r\n",
      "Collecting feature_engine\r\n",
      "  Downloading feature_engine-1.6.2-py2.py3-none-any.whl (328 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.9/328.9 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pyCausalFS) (1.23.5)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from pyCausalFS) (2.0.3)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyCausalFS) (1.2.2)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from pyCausalFS) (3.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from pyCausalFS) (3.7.2)\r\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from feature_engine) (0.14.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->pyCausalFS) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->pyCausalFS) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->pyCausalFS) (2023.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyCausalFS) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyCausalFS) (3.1.0)\r\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.11.1->feature_engine) (21.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyCausalFS) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyCausalFS) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyCausalFS) (4.40.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyCausalFS) (1.4.4)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyCausalFS) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyCausalFS) (3.0.9)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature_engine) (1.16.0)\r\n",
      "Installing collected packages: pyCausalFS, feature_engine\r\n",
      "Successfully installed feature_engine-1.6.2 pyCausalFS-0.23\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyCausalFS tabulate xgboost scipy feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87752a0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:02.574065Z",
     "iopub.status.busy": "2023-10-31T00:43:02.573795Z",
     "iopub.status.idle": "2023-10-31T00:43:04.497121Z",
     "shell.execute_reply": "2023-10-31T00:43:04.496467Z"
    },
    "papermill": {
     "duration": 1.932418,
     "end_time": "2023-10-31T00:43:04.499150",
     "exception": false,
     "start_time": "2023-10-31T00:43:02.566732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from pyCausalFS.CBD.MBs.IAMB import IAMB\n",
    "from pyCausalFS.CBD.MBs.BAMB import BAMB\n",
    "from pyCausalFS.CBD.MBs.STMB import STMB\n",
    "from pyCausalFS.CBD.MBs.MBOR import MBOR\n",
    "from pyCausalFS.CBD.MBs.LCMB import LRH\n",
    "from pyCausalFS.CBD.MBs.MMMB.MMMB import MMMB\n",
    "from pyCausalFS.CBD.MBs.HITON.HITON_MB import HITON_MB\n",
    "from pyCausalFS.CBD.MBs.HITON.HITON_PC import HITON_PC\n",
    "from pyCausalFS.CBD.MBs.MMMB.MMPC import MMPC\n",
    "from pyCausalFS.CBD.MBs.GSMB import GSMB\n",
    "from pyCausalFS.CBD.MBs.fast_IAMB import fast_IAMB\n",
    "from pyCausalFS.CBD.MBs.inter_IAMB import inter_IAMB\n",
    "from pyCausalFS.CBD.MBs.IAMBnPC import IAMBnPC\n",
    "from pyCausalFS.CBD.MBs.interIAMBnPC import interIAMBnPC\n",
    "from pyCausalFS.CBD.MBs.FBEDk import FBED\n",
    "from pyCausalFS.CBD.MBs.PCMB.PCMB import PCMB\n",
    "from pyCausalFS.CBD.MBs.semi_HITON.semi_HITON_MB import semi_HITON_MB\n",
    "from pyCausalFS.CBD.MBs.IPCMB.IPCMB import IPC_MB\n",
    "from pyCausalFS.LSL.MBs.PCDbyPCD import PCDbyPCD\n",
    "from pyCausalFS.LSL.MBs.MBbyMB import MBbyMB\n",
    "from pyCausalFS.LSL.MBs.CMB.CMB import CMB\n",
    "from pyCausalFS.CBD.MBs.KIAMB import KIAMB\n",
    "from pyCausalFS.CBD.MBs.TIE_star.TIEs import TIE_p\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef as mcc_score,  roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from scipy.io import arff\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, f_classif, RFECV, SequentialFeatureSelector\n",
    "from feature_engine.selection import DropCorrelatedFeatures, SmartCorrelatedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edc7021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.513069Z",
     "iopub.status.busy": "2023-10-31T00:43:04.512731Z",
     "iopub.status.idle": "2023-10-31T00:43:04.516153Z",
     "shell.execute_reply": "2023-10-31T00:43:04.515401Z"
    },
    "papermill": {
     "duration": 0.01204,
     "end_time": "2023-10-31T00:43:04.517750",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.505710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "significance_val = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f160f",
   "metadata": {
    "papermill": {
     "duration": 0.005789,
     "end_time": "2023-10-31T00:43:04.529695",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.523906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Selection Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfd576f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.542548Z",
     "iopub.status.busy": "2023-10-31T00:43:04.542328Z",
     "iopub.status.idle": "2023-10-31T00:43:04.560938Z",
     "shell.execute_reply": "2023-10-31T00:43:04.560336Z"
    },
    "papermill": {
     "duration": 0.026769,
     "end_time": "2023-10-31T00:43:04.562500",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.535731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findGSMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = GSMB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findIAMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = IAMB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findInterIAMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = inter_IAMB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findFastIAMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = fast_IAMB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findIAMBnPC(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = IAMBnPC(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "    \n",
    "def findinterIAMBnPC(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = interIAMBnPC(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findLRH(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = LRH(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findBAMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = BAMB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "\n",
    "def findFBEDk(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = FBED(df, index, 15, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findMMMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = MMMB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findPCMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = PCMB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findHITON_MB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = HITON_MB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findSemi_HITON_MB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = semi_HITON_MB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findMBOR(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = MBOR(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findIPCMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = IPC_MB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findSTMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MB, ci_num = STMB(df, index, alpha, isDiscrete)\n",
    "        return MB\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findKIAMB(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MBList = []\n",
    "        for i in range(0, 100):\n",
    "            MB, ci_num = KIAMB(df, index, alpha, 0.1, isDiscrete)\n",
    "            MBList.append(MB)\n",
    "        MB = set()\n",
    "        for mb in MBList:\n",
    "            for x in mb:\n",
    "                MB.add(x)\n",
    "        return list(MB)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "\n",
    "def findTIE_P(df, index, alpha, isDiscrete):\n",
    "    try:\n",
    "        MBList = TIE_p(df, index, alpha, isDiscrete)\n",
    "        MB = set()\n",
    "        for mb in MBList:\n",
    "            for x in mb:\n",
    "                MB.add(x)\n",
    "        return list(MB)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1367946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.575461Z",
     "iopub.status.busy": "2023-10-31T00:43:04.575207Z",
     "iopub.status.idle": "2023-10-31T00:43:04.627297Z",
     "shell.execute_reply": "2023-10-31T00:43:04.626480Z"
    },
    "papermill": {
     "duration": 0.060676,
     "end_time": "2023-10-31T00:43:04.629190",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.568514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findChiSquare1(df, index, alpha, isDicrete):\n",
    "    try:\n",
    "        X = df.drop(columns=[df.columns[-1]]).values\n",
    "        y = df[df.columns[-1]].values\n",
    "        SelectBest = SelectKBest(chi2, k=4).fit(X, y)\n",
    "        features = SelectBest.get_feature_names_out(range(0, index))\n",
    "        return features.astype(int)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findChiSquare2(df, index, alpha, isDicrete):\n",
    "    try:\n",
    "        X = df.drop(columns=[df.columns[-1]]).values\n",
    "        y = df[df.columns[-1]].values\n",
    "        SelectBest = SelectKBest(chi2, k=6).fit(X, y)\n",
    "        features = SelectBest.get_feature_names_out(range(0, index))\n",
    "        return features.astype(int)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findChiSquare3(df, index, alpha, isDicrete):\n",
    "    try:\n",
    "        X = df.drop(columns=[df.columns[-1]]).values\n",
    "        y = df[df.columns[-1]].values\n",
    "        SelectBest = SelectKBest(chi2, k=8).fit(X, y)\n",
    "        features = SelectBest.get_feature_names_out(range(0, index))\n",
    "        return features.astype(int)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findChiSquare4(df, index, alpha, isDicrete):\n",
    "    try:\n",
    "        X = df.drop(columns=[df.columns[-1]]).values\n",
    "        y = df[df.columns[-1]].values\n",
    "        SelectBest = SelectKBest(chi2, k=10).fit(X, y)\n",
    "        features = SelectBest.get_feature_names_out(range(0, index))\n",
    "        return features.astype(int)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findChiSquare5(df, index, alpha, isDicrete):\n",
    "    try:\n",
    "        X = df.drop(columns=[df.columns[-1]]).values\n",
    "        y = df[df.columns[-1]].values\n",
    "        SelectBest = SelectKBest(chi2, k=12).fit(X, y)\n",
    "        features = SelectBest.get_feature_names_out(range(0, index))\n",
    "        return features.astype(int)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def findMutualInfo1(df, index, alpha, isDicrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(mutual_info_classif, k=4).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findMutualInfo2(df, index, alpha, isDicrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(mutual_info_classif, k=6).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findMutualInfo3(df, index, alpha, isDicrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(mutual_info_classif, k=8).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "\n",
    "def findMutualInfo4(df, index, alpha, isDicrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(mutual_info_classif, k=10).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findMutualInfo5(df, index, alpha, isDicrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(mutual_info_classif, k=12).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findAnovaFeat1(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(f_classif, k=4).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findAnovaFeat2(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(f_classif, k=6).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findAnovaFeat3(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(f_classif, k=8).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findAnovaFeat4(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(f_classif, k=10).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findAnovaFeat5(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    SelectBest = SelectKBest(f_classif, k=12).fit(X, y)\n",
    "    features = SelectBest.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findCorrelatedFeat1(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    dcf = DropCorrelatedFeatures(threshold=0.3).fit(X, y)\n",
    "    features = dcf.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "def findCorrelatedFeat2(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    dcf = DropCorrelatedFeatures(threshold=0.4).fit(X, y)\n",
    "    features = dcf.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "\n",
    "def findCorrelatedFeat3(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    dcf = DropCorrelatedFeatures(threshold=0.5).fit(X, y)\n",
    "    features = dcf.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "\n",
    "def findCorrelatedFeat4(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    dcf = DropCorrelatedFeatures(threshold=0.6).fit(X, y)\n",
    "    features = dcf.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "def findCorrelatedFeat5(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    dcf = DropCorrelatedFeatures(threshold=0.7).fit(X, y)\n",
    "    features = dcf.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "def findSmartCorrelatedFeat1(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    scs = SmartCorrelatedSelection(threshold=0.3).fit(X, y)\n",
    "    features = scs.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "def findSmartCorrelatedFeat2(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    scs = SmartCorrelatedSelection(threshold=0.4).fit(X, y)\n",
    "    features = scs.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "def findSmartCorrelatedFeat3(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    scs = SmartCorrelatedSelection(threshold=0.5).fit(X, y)\n",
    "    features = scs.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "def findSmartCorrelatedFeat4(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    scs = SmartCorrelatedSelection(threshold=0.6).fit(X, y)\n",
    "    features = scs.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "def findSmartCorrelatedFeat5(df, index, alpha, isDiscrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    scs = SmartCorrelatedSelection(threshold=0.7).fit(X, y)\n",
    "    features = scs.get_feature_names_out(range(0, index))\n",
    "    features = [int(x) for x in features]\n",
    "    return features\n",
    "\n",
    "def RFELogistic(df, index, alpha, isDicrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    min_features_to_select = 1\n",
    "    clf = LogisticRegression()\n",
    "    cv = model_selection.StratifiedKFold(5)\n",
    "\n",
    "    rfecv = RFECV(\n",
    "        estimator=clf,\n",
    "        step=1,\n",
    "        cv=cv,\n",
    "        scoring=\"roc_auc\",\n",
    "        min_features_to_select=min_features_to_select,\n",
    "    )\n",
    "    rfecv.fit(X, y)\n",
    "    return rfecv.ranking_\n",
    "\n",
    "def RFERandom(df, index, alpha, isDicrete):\n",
    "    X = df.drop(columns=[df.columns[-1]]).values\n",
    "    y = df[df.columns[-1]].values\n",
    "    min_features_to_select = 1\n",
    "    clf = RandomForestClassifier()\n",
    "    cv = model_selection.StratifiedKFold(5)\n",
    "\n",
    "    rfecv = RFECV(\n",
    "        estimator=clf,\n",
    "        step=1,\n",
    "        cv=cv,\n",
    "        scoring=\"roc_auc\",\n",
    "        min_features_to_select=min_features_to_select,\n",
    "    )\n",
    "    rfecv.fit(X, y)\n",
    "    return rfecv.ranking_\n",
    "\n",
    "def findRFELogistic1(df, index, alpha, isDiscrete):\n",
    "    k = 4\n",
    "    ranking = RFELogistic(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findRFELogistic2(df, index, alpha, isDiscrete):\n",
    "    k = 6\n",
    "    ranking = RFELogistic(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findRFELogistic3(df, index, alpha, isDiscrete):\n",
    "    k = 8\n",
    "    ranking = RFELogistic(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findRFELogistic4(df, index, alpha, isDiscrete):\n",
    "    k = 10\n",
    "    ranking = RFELogistic(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findRFELogistic5(df, index, alpha, isDiscrete):\n",
    "    k = 12\n",
    "    ranking = RFELogistic(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findRFERandom1(df, index, alpha, isDiscrete):\n",
    "    k = 4\n",
    "    ranking = RFERandom(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findRFERandom2(df, index, alpha, isDiscrete):\n",
    "    k = 6\n",
    "    ranking = RFERandom(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findRFERandom3(df, index, alpha, isDiscrete):\n",
    "    k = 8\n",
    "    ranking = RFERandom(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findRFERandom4(df, index, alpha, isDiscrete):\n",
    "    k = 10\n",
    "    ranking = RFERandom(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findRFERandom5(df, index, alpha, isDiscrete):\n",
    "    k = 12\n",
    "    ranking = RFERandom(df, index, alpha, isDiscrete)\n",
    "    ind = np.argsort(ranking)[-k:]\n",
    "    return ind\n",
    "\n",
    "def findForward1(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=4, scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findForward2(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=6, scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findForward3(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=8, scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findForward4(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=10, scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findForward5(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=12, scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findBackward1(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=4, direction='backward', scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findBackward2(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=6, direction='backward', scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findBackward3(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=8, direction='backward', scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findBackward4(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=10, direction='backward', scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)\n",
    "\n",
    "def findBackward5(df, index, alpha, isDiscrete):\n",
    "    clf = LogisticRegression()\n",
    "    sfs = SequentialFeatureSelector(clf, n_features_to_select=12,direction='backward', scoring=\"roc_auc\")\n",
    "    sfs.fit(X, y)\n",
    "    features = sfs.get_feature_names_out(range(0, index))\n",
    "    return features.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ef2499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.642727Z",
     "iopub.status.busy": "2023-10-31T00:43:04.642450Z",
     "iopub.status.idle": "2023-10-31T00:43:04.647794Z",
     "shell.execute_reply": "2023-10-31T00:43:04.647149Z"
    },
    "papermill": {
     "duration": 0.013767,
     "end_time": "2023-10-31T00:43:04.649354",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.635587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_algo = {\n",
    "# Causal \n",
    "#     'GSMB': findGSMB,\n",
    "#     'IAMB': findIAMB,\n",
    "#     'IAMBnPC': findIAMBnPC,\n",
    "#     'LRH': findLRH,\n",
    "#     'BAMB': findBAMB,\n",
    "#     'FBEDk': findFBEDk,\n",
    "#     'MMMB': findMMMB,\n",
    "#     'PCMB': findPCMB,\n",
    "#     'HITON_MB': findHITON_MB,\n",
    "#     'MBOR': findMBOR,\n",
    "#     'IPCMB': findIPCMB,\n",
    "#     'STMB': findSTMB,\n",
    "#     'KIAMB': findKIAMB,\n",
    "#     'TIE_P': findTIE_P,\n",
    "    \n",
    "# None-Causal\n",
    "#     'Chi-Square1': findChiSquare1,\n",
    "#     'Chi-Square2': findChiSquare2,\n",
    "#     'Chi-Square3': findChiSquare3,\n",
    "#     'Chi-Square4': findChiSquare4,\n",
    "#     'Chi-Square5': findChiSquare5,\n",
    "    \n",
    "#     'Mutual-Info1': findMutualInfo1,\n",
    "#     'Mutual-Info2': findMutualInfo2,\n",
    "#     'Mutual-Info3': findMutualInfo3,\n",
    "#     'Mutual-Info4': findMutualInfo4,\n",
    "#     'Mutual-Info5': findMutualInfo5,\n",
    "    \n",
    "#     'Anova1': findAnovaFeat1,\n",
    "#     'Anova2': findAnovaFeat2,\n",
    "#     'Anova3': findAnovaFeat3,\n",
    "#     'Anova4': findAnovaFeat4,\n",
    "#     'Anova5': findAnovaFeat5,\n",
    "    \n",
    "#     'DropCorrelated1': findCorrelatedFeat1,\n",
    "#     'DropCorrelated2': findCorrelatedFeat2,\n",
    "#     'DropCorrelated3': findCorrelatedFeat3,\n",
    "#     'DropCorrelated4': findCorrelatedFeat4,\n",
    "#     'DropCorrelated5': findCorrelatedFeat5,\n",
    "    \n",
    "#     'SmartCorrelated1': findSmartCorrelatedFeat1,\n",
    "#     'SmartCorrelated2': findSmartCorrelatedFeat2,\n",
    "#     'SmartCorrelated3': findSmartCorrelatedFeat3,\n",
    "#     'SmartCorrelated4': findSmartCorrelatedFeat4,\n",
    "#     'SmartCorrelated5': findSmartCorrelatedFeat5,\n",
    "    \n",
    "#     'RFE-Logistic1': findRFELogistic1,\n",
    "#     'RFE-Logistic2': findRFELogistic2,\n",
    "#     'RFE-Logistic3': findRFELogistic3,\n",
    "#     'RFE-Logistic4': findRFELogistic4,\n",
    "#     'RFE-Logistic5': findRFELogistic5,\n",
    "    \n",
    "#     'RFE-Random1': findRFERandom1,\n",
    "#     'RFE-Random2': findRFERandom2,\n",
    "#     'RFE-Random3': findRFERandom3,\n",
    "#     'RFE-Random4': findRFERandom4,\n",
    "#     'RFE-Random5': findRFERandom5,\n",
    "    \n",
    "#     'Forward1': findForward1,\n",
    "#     'Forward2': findForward2,\n",
    "#     'Forward3': findForward3,\n",
    "#     'Forward4': findForward4,\n",
    "#     'Forward5': findForward5,\n",
    "    \n",
    "#     'Backward1': findBackward1,\n",
    "    'Backward2': findBackward2,\n",
    "    'Backward3': findBackward3,\n",
    "    'Backward4': findBackward4,\n",
    "#     'Backward5': findBackward5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df1e279",
   "metadata": {
    "papermill": {
     "duration": 0.005662,
     "end_time": "2023-10-31T00:43:04.661070",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.655408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9275e522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.674111Z",
     "iopub.status.busy": "2023-10-31T00:43:04.673871Z",
     "iopub.status.idle": "2023-10-31T00:43:04.677547Z",
     "shell.execute_reply": "2023-10-31T00:43:04.676801Z"
    },
    "papermill": {
     "duration": 0.012241,
     "end_time": "2023-10-31T00:43:04.679191",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.666950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_list_of_csv(folder_path):\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab07f55",
   "metadata": {
    "papermill": {
     "duration": 0.005739,
     "end_time": "2023-10-31T00:43:04.690874",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.685135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### AEEEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac3dab87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.704161Z",
     "iopub.status.busy": "2023-10-31T00:43:04.703619Z",
     "iopub.status.idle": "2023-10-31T00:43:04.709146Z",
     "shell.execute_reply": "2023-10-31T00:43:04.708250Z"
    },
    "papermill": {
     "duration": 0.014192,
     "end_time": "2023-10-31T00:43:04.710900",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.696708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_aeeem_dataset(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df.rename(columns={df.columns[-1]: 'temp'}, inplace=True)\n",
    "    columns_to_drop = ['temp', 'classname', 'nonTrivialBugs', 'majorBugs', 'criticalBugs', 'highPriorityBugs']\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    df.loc[df['bugs'] > 0, 'bugs'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0543f170",
   "metadata": {
    "papermill": {
     "duration": 0.005808,
     "end_time": "2023-10-31T00:43:04.722798",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.716990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### JIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c636936d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.735703Z",
     "iopub.status.busy": "2023-10-31T00:43:04.735445Z",
     "iopub.status.idle": "2023-10-31T00:43:04.739350Z",
     "shell.execute_reply": "2023-10-31T00:43:04.738660Z"
    },
    "papermill": {
     "duration": 0.012168,
     "end_time": "2023-10-31T00:43:04.740837",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.728669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_jira_dataset(df):\n",
    "    columns_to_drop = ['File', 'RealBug', 'HeuBug', 'HeuBugCount']\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    df.loc[df['RealBugCount'] > 0, 'RealBugCount'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf49af",
   "metadata": {
    "papermill": {
     "duration": 0.005951,
     "end_time": "2023-10-31T00:43:04.752866",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.746915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TERA-PROMISE-ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2125d60b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.765622Z",
     "iopub.status.busy": "2023-10-31T00:43:04.765362Z",
     "iopub.status.idle": "2023-10-31T00:43:04.769385Z",
     "shell.execute_reply": "2023-10-31T00:43:04.768718Z"
    },
    "papermill": {
     "duration": 0.01217,
     "end_time": "2023-10-31T00:43:04.770893",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.758723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_promise_ck_dataset(df):\n",
    "    columns_to_drop = ['Name', 'version']\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=columns_to_drop)  \n",
    "    df.loc[df['bug'] > 0, 'bug'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98204b7b",
   "metadata": {
    "papermill": {
     "duration": 0.005817,
     "end_time": "2023-10-31T00:43:04.782619",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.776802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184a06fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.795446Z",
     "iopub.status.busy": "2023-10-31T00:43:04.795176Z",
     "iopub.status.idle": "2023-10-31T00:43:04.802433Z",
     "shell.execute_reply": "2023-10-31T00:43:04.801729Z"
    },
    "papermill": {
     "duration": 0.015421,
     "end_time": "2023-10-31T00:43:04.803957",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.788536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_list = {\n",
    "#     \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "#     \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "#     \"XgBoost\": XGBClassifier(),\n",
    "#     \"Random Forest\": RandomForestClassifier(),\n",
    "#     \"SVM\":  svm.SVC(kernel='rbf')\n",
    "}\n",
    "models_search_params = {\n",
    "    \"KNN\": {  \n",
    "        'n_neighbors' : [3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31],\n",
    "        'weights' : ['uniform','distance'],\n",
    "        'metric' : ['minkowski','euclidean','manhattan']\n",
    "     },\n",
    "    \"Logistic Regression\": {\n",
    "        'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "        'C' : [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'solver' : ['lbfgs','newton-cg','liblinear', 'newton-cholesky', 'sag', 'saga'],\n",
    "        'max_iter' : [100, 1500, 3000]\n",
    "     },\n",
    "    \"Decision Tree\": {\n",
    "        'max_features': [1, 2, 3, 5, 7, 10, 'log2','sqrt', None],\n",
    "        'max_depth': [2, 3, 5, 7, 10, 20, 30, 40, 50, 60, 70, None],\n",
    "        'min_samples_split': [1, 2, 3, 5, 7, 9, 10, 0.1, 0.2, 0.3],\n",
    "        'min_samples_leaf': [1, 2, 3, 5, 7, 9, 10, 0.1, 0.2],\n",
    "     },\n",
    "    \"Random Forest\": {\n",
    "        'max_depth': [2, 5, 10, None],\n",
    "        'max_features': ['log2', 'sqrt', None],\n",
    "    },\n",
    "    \"XgBoost\": {\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 6, 10],\n",
    "        'subsample': [0.5, 0.7, 1],\n",
    "        'n_estimators': [100, 500]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a835a0d5",
   "metadata": {
    "papermill": {
     "duration": 0.005854,
     "end_time": "2023-10-31T00:43:04.815654",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.809800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c413f65e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.828181Z",
     "iopub.status.busy": "2023-10-31T00:43:04.827967Z",
     "iopub.status.idle": "2023-10-31T00:43:04.833539Z",
     "shell.execute_reply": "2023-10-31T00:43:04.832826Z"
    },
    "papermill": {
     "duration": 0.013575,
     "end_time": "2023-10-31T00:43:04.835059",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.821484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def g_measure_score(y_test, y_pred):\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "    FPR = FP/(FP+TN)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    g_measure = (2*recall*(1-FPR))/(recall+(1-FPR))\n",
    "    return g_measure\n",
    "\n",
    "def bal_score(y_test, y_pred):\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    FPR = FP/(FP+TN)\n",
    "    PF = FPR\n",
    "    PD = recall\n",
    "    bal = 1 - (math.sqrt((1-PD)*(1-PD)+(0-PF)*(0-PF))/math.sqrt(2))\n",
    "    return bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d0746f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.848075Z",
     "iopub.status.busy": "2023-10-31T00:43:04.847498Z",
     "iopub.status.idle": "2023-10-31T00:43:04.851902Z",
     "shell.execute_reply": "2023-10-31T00:43:04.851377Z"
    },
    "papermill": {
     "duration": 0.01258,
     "end_time": "2023-10-31T00:43:04.853446",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.840866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_model_params(X_train, y_train, model):\n",
    "    classifier = models_list[model]\n",
    "    cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_obj = RandomizedSearchCV(classifier, models_search_params[model], n_iter = 15, cv = cv, scoring='roc_auc')\n",
    "    grid_obj.fit(X_train, y_train)\n",
    "    best_model_params = grid_obj.best_params_\n",
    "    return best_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e1e71d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.866469Z",
     "iopub.status.busy": "2023-10-31T00:43:04.865939Z",
     "iopub.status.idle": "2023-10-31T00:43:04.876746Z",
     "shell.execute_reply": "2023-10-31T00:43:04.876238Z"
    },
    "papermill": {
     "duration": 0.019055,
     "end_time": "2023-10-31T00:43:04.878336",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.859281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(file_name, X, y, model, feat_algo):\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    mcc_scores = []\n",
    "    roc_auc_scores = []\n",
    "    g_measure_scores = []\n",
    "    bal_scores = []\n",
    "\n",
    "    best_model_params = {}\n",
    "    MB = []\n",
    "    \n",
    "    kf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        adasyn = ADASYN()\n",
    "        X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "        \n",
    "        if feat_algo != 'None' and len(MB)<1:\n",
    "            balanced_df = pd.concat([pd.DataFrame(X_train), pd.Series(y_train, name='bug')], axis=1)\n",
    "            MB = feature_algo[feat_algo](balanced_df, balanced_df.shape[1]-1, significance_val, False)\n",
    "            print(file_name, feat_algo, balanced_df.shape[1]-1, MB)\n",
    "            \n",
    "        if len(MB) >= 1 and feat_algo != 'None':\n",
    "            X_train = X_train[:, MB]\n",
    "            X_test = X_test[:, MB]\n",
    "        elif feat_algo != 'None':\n",
    "            return [file_name, feat_algo, '--', '--', '--', '--', '--', '--', '--']\n",
    "        \n",
    "        if not best_model_params:\n",
    "            best_model_params = get_best_model_params(X_train, y_train, model)\n",
    "            print(file_name, feat_algo, model, best_model_params)\n",
    "            \n",
    "        classifier = models_list[model]\n",
    "        classifier.set_params(**best_model_params)\n",
    "        \n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        \n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        mcc_scores.append(mcc_score(y_test, y_pred))\n",
    "        roc_auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "        g_measure_scores.append(g_measure_score(y_test, y_pred))\n",
    "        bal_scores.append(bal_score(y_test, y_pred))\n",
    "    \n",
    "    return [file_name, feat_algo, round(np.mean(accuracy_scores),2), round(np.mean(precision_scores), 2), round(np.mean(recall_scores), 2), round(np.mean(f1_scores), 2), round(np.mean(mcc_scores), 2), round(np.mean(roc_auc_scores),2), round(np.mean(g_measure_scores), 2), round(np.mean(bal_scores), 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f1d21",
   "metadata": {
    "papermill": {
     "duration": 0.00572,
     "end_time": "2023-10-31T00:43:04.889837",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.884117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3ba55",
   "metadata": {
    "papermill": {
     "duration": 0.005582,
     "end_time": "2023-10-31T00:43:04.901173",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.895591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TERA-PROMISE-ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c148aa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T00:43:04.913876Z",
     "iopub.status.busy": "2023-10-31T00:43:04.913656Z",
     "iopub.status.idle": "2023-10-31T01:15:52.485221Z",
     "shell.execute_reply": "2023-10-31T01:15:52.484209Z"
    },
    "papermill": {
     "duration": 1967.579919,
     "end_time": "2023-10-31T01:15:52.486857",
     "exception": false,
     "start_time": "2023-10-31T00:43:04.906938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Logistic Regression ---------------------------\n",
      "prop-3.csv Backward2 20 [ 1  2  6  7 13 19]\n",
      "prop-3.csv Backward2 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.01}\n",
      "prop-3.csv Backward3 20 [ 1  2  3  6  7 13 14 19]\n",
      "prop-3.csv Backward3 Logistic Regression {'solver': 'sag', 'penalty': 'l2', 'max_iter': 3000, 'C': 1000}\n",
      "prop-3.csv Backward4 20 [ 1  2  3  6  7 11 12 13 14 19]\n",
      "prop-3.csv Backward4 Logistic Regression {'solver': 'saga', 'penalty': 'l2', 'max_iter': 1500, 'C': 100}\n",
      "prop-4.csv Backward2 20 [ 2  4  5  8 14 19]\n",
      "prop-4.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 100, 'C': 0.1}\n",
      "prop-4.csv Backward3 20 [ 2  4  5  7  8 11 14 19]\n",
      "prop-4.csv Backward3 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 100, 'C': 0.01}\n",
      "prop-4.csv Backward4 20 [ 2  3  4  5  7  8 11 13 14 19]\n",
      "prop-4.csv Backward4 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 3000, 'C': 0.01}\n",
      "prop-2.csv Backward2 20 [ 0  1  3  4  9 12]\n",
      "prop-2.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 100}\n",
      "prop-2.csv Backward3 20 [ 0  1  3  4  6  9 12 16]\n",
      "prop-2.csv Backward3 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.001}\n",
      "prop-2.csv Backward4 20 [ 0  1  3  4  5  6  9 10 12 16]\n",
      "prop-2.csv Backward4 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.01}\n",
      "prop-1.csv Backward2 20 [ 4  7 11 12 14 17]\n",
      "prop-1.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 0.01}\n",
      "prop-1.csv Backward3 20 [ 1  4  7 11 12 14 17 19]\n",
      "prop-1.csv Backward3 Logistic Regression {'solver': 'sag', 'penalty': 'l2', 'max_iter': 100, 'C': 0.01}\n",
      "prop-1.csv Backward4 20 [ 1  3  4  7 11 12 14 17 18 19]\n",
      "prop-1.csv Backward4 Logistic Regression {'solver': 'saga', 'penalty': 'l1', 'max_iter': 1500, 'C': 0.01}\n",
      "prop-5.csv Backward2 20 [ 1  6  7 13 17 19]\n",
      "prop-5.csv Backward2 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 3000, 'C': 1}\n",
      "prop-5.csv Backward3 20 [ 0  1  6  7  8 13 17 19]\n",
      "prop-5.csv Backward3 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.1}\n",
      "prop-5.csv Backward4 20 [ 0  1  6  7  8 11 13 15 17 19]\n",
      "prop-5.csv Backward4 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 3000, 'C': 1}\n",
      "----------  ---------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "dataset     feat_algo  acc       prec      recall    f1        mcc       roc_auc   g-m       bal\n",
      "prop-3.csv  Backward2  0.68      0.57      0.65      0.55      0.2       0.65      0.67      0.67\n",
      "prop-3.csv  Backward3  0.66      0.57      0.65      0.54      0.2       0.65      0.66      0.66\n",
      "prop-3.csv  Backward4  0.67      0.57      0.65      0.54      0.2       0.65      0.66      0.66\n",
      "--------    --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "prop-4.csv  Backward2  0.7       0.56      0.66      0.55      0.2       0.66      0.68      0.68\n",
      "prop-4.csv  Backward3  0.71      0.58      0.69      0.56      0.24      0.69      0.7       0.7\n",
      "prop-4.csv  Backward4  0.71      0.58      0.69      0.56      0.25      0.69      0.71      0.71\n",
      "--------    --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "prop-2.csv  Backward2  0.63      0.56      0.65      0.52      0.19      0.65      0.64      0.64\n",
      "prop-2.csv  Backward3  0.66      0.56      0.63      0.53      0.17      0.63      0.65      0.65\n",
      "prop-2.csv  Backward4  0.65      0.56      0.64      0.52      0.18      0.64      0.64      0.64\n",
      "--------    --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "prop-1.csv  Backward2  0.72      0.59      0.64      0.59      0.22      0.64      0.69      0.69\n",
      "prop-1.csv  Backward3  0.71      0.58      0.64      0.58      0.21      0.64      0.69      0.69\n",
      "prop-1.csv  Backward4  0.71      0.59      0.65      0.59      0.23      0.65      0.69      0.69\n",
      "--------    --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "prop-5.csv  Backward2  0.64      0.58      0.64      0.55      0.21      0.64      0.64      0.64\n",
      "prop-5.csv  Backward3  0.64      0.58      0.64      0.55      0.21      0.64      0.64      0.64\n",
      "prop-5.csv  Backward4  0.64      0.58      0.65      0.55      0.21      0.65      0.64      0.64\n",
      "--------    --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "----------  ---------  --------  --------  --------  --------  --------  --------  --------  --------\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/kaggle/input/defect-prediction/TeraPromise-defect-dataset/ck'\n",
    "files_list = get_list_of_csv(folder_path)\n",
    "\n",
    "for model in models_list.keys():\n",
    "    print('----------------',model,'---------------------------')\n",
    "    table = []\n",
    "    table.append([\"dataset\", \"feat_algo\", \"acc\", \"prec\", \"recall\", \"f1\", \"mcc\", \"roc_auc\", \"g-m\", \"bal\"])\n",
    "    for file_name in files_list:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if df.shape[0]<=1500:\n",
    "            continue\n",
    "        \n",
    "        df = process_promise_ck_dataset(df)\n",
    "        X = df.drop(columns=[df.columns[-1]]).values\n",
    "        y = df[df.columns[-1]].values\n",
    "        \n",
    "#         table.append(build_model(file_name, X, y, model, 'None'))\n",
    "        for feat_algo in feature_algo.keys():\n",
    "            table.append(build_model(file_name, X, y, model, feat_algo))\n",
    "        table.append(['--------', '--------', '--------', '--------', '--------', '--------', '--------', '--------', '--------', '--------'])\n",
    "    print(tabulate(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4581e53",
   "metadata": {
    "papermill": {
     "duration": 0.007692,
     "end_time": "2023-10-31T01:15:52.502719",
     "exception": false,
     "start_time": "2023-10-31T01:15:52.495027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### JIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52dd6ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:15:52.519163Z",
     "iopub.status.busy": "2023-10-31T01:15:52.518920Z",
     "iopub.status.idle": "2023-10-31T07:25:18.713282Z",
     "shell.execute_reply": "2023-10-31T07:25:18.712375Z"
    },
    "papermill": {
     "duration": 22166.204673,
     "end_time": "2023-10-31T07:25:18.715038",
     "exception": false,
     "start_time": "2023-10-31T01:15:52.510365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Logistic Regression ---------------------------\n",
      "camel-2.11.0.csv Backward2 65 [32 35 40 41 45 56]\n",
      "camel-2.11.0.csv Backward2 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.1}\n",
      "camel-2.11.0.csv Backward3 65 [18 32 35 40 41 43 45 56]\n",
      "camel-2.11.0.csv Backward3 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 100, 'C': 0.1}\n",
      "camel-2.11.0.csv Backward4 65 [ 9 18 32 35 40 41 43 45 53 56]\n",
      "camel-2.11.0.csv Backward4 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 1500, 'C': 1000}\n",
      "derby-10.5.1.1.csv Backward2 65 [19 21 44 48 49 59]\n",
      "derby-10.5.1.1.csv Backward2 Logistic Regression {'solver': 'saga', 'penalty': 'l1', 'max_iter': 100, 'C': 1000}\n",
      "derby-10.5.1.1.csv Backward3 65 [15 19 21 29 44 48 49 59]\n",
      "derby-10.5.1.1.csv Backward3 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.01}\n",
      "derby-10.5.1.1.csv Backward4 65 [12 15 19 21 29 41 44 48 49 59]\n",
      "derby-10.5.1.1.csv Backward4 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 100, 'C': 0.1}\n",
      "activemq-5.3.0.csv Backward2 65 [20 40 42 53 62 63]\n",
      "activemq-5.3.0.csv Backward2 Logistic Regression {'solver': 'saga', 'penalty': 'l1', 'max_iter': 1500, 'C': 1000}\n",
      "activemq-5.3.0.csv Backward3 65 [ 0 20 40 42 43 53 62 63]\n",
      "activemq-5.3.0.csv Backward3 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.1}\n",
      "activemq-5.3.0.csv Backward4 65 [ 0 20 40 42 43 44 53 56 62 63]\n",
      "activemq-5.3.0.csv Backward4 Logistic Regression {'solver': 'saga', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.1}\n",
      "derby-10.3.1.4.csv Backward2 65 [ 2 18 31 33 57 58]\n",
      "derby-10.3.1.4.csv Backward2 Logistic Regression {'solver': 'saga', 'penalty': 'l2', 'max_iter': 3000, 'C': 1}\n",
      "derby-10.3.1.4.csv Backward3 65 [ 1  2 18 23 31 33 57 58]\n",
      "derby-10.3.1.4.csv Backward3 Logistic Regression {'solver': 'saga', 'penalty': 'l2', 'max_iter': 100, 'C': 100}\n",
      "derby-10.3.1.4.csv Backward4 65 [ 1  2 18 23 26 31 33 50 57 58]\n",
      "derby-10.3.1.4.csv Backward4 Logistic Regression {'solver': 'saga', 'penalty': 'l1', 'max_iter': 100, 'C': 0.001}\n",
      "activemq-5.2.0.csv Backward2 65 [22 26 31 40 55 58]\n",
      "activemq-5.2.0.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 3000, 'C': 1}\n",
      "activemq-5.2.0.csv Backward3 65 [17 22 26 31 40 55 58 60]\n",
      "activemq-5.2.0.csv Backward3 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 1500, 'C': 1000}\n",
      "activemq-5.2.0.csv Backward4 65 [ 7 17 22 26 31 40 42 55 58 60]\n",
      "activemq-5.2.0.csv Backward4 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 100, 'C': 0.001}\n",
      "hive-0.12.0.csv Backward2 65 [13 29 46 50 55 63]\n",
      "hive-0.12.0.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 3000, 'C': 0.1}\n",
      "hive-0.12.0.csv Backward3 65 [ 5 13 20 29 46 50 55 63]\n",
      "hive-0.12.0.csv Backward3 Logistic Regression {'solver': 'sag', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.0001}\n",
      "hive-0.12.0.csv Backward4 65 [ 5 13 20 29 46 50 52 55 59 63]\n",
      "hive-0.12.0.csv Backward4 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.01}\n",
      "camel-2.10.0.csv Backward2 65 [ 5 16 32 38 40 55]\n",
      "camel-2.10.0.csv Backward2 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 100, 'C': 10}\n",
      "camel-2.10.0.csv Backward3 65 [ 5 16 17 21 32 38 40 55]\n",
      "camel-2.10.0.csv Backward3 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 1000}\n",
      "camel-2.10.0.csv Backward4 65 [ 5 16 17 21 22 32 38 40 51 55]\n",
      "camel-2.10.0.csv Backward4 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 100, 'C': 0.001}\n",
      "derby-10.2.1.6.csv Backward2 65 [18 29 52 55 60 64]\n",
      "derby-10.2.1.6.csv Backward2 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 3000, 'C': 100}\n",
      "derby-10.2.1.6.csv Backward3 65 [16 18 29 35 52 55 60 64]\n",
      "derby-10.2.1.6.csv Backward3 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 1500, 'C': 100}\n",
      "derby-10.2.1.6.csv Backward4 65 [16 18 25 29 35 52 55 59 60 64]\n",
      "derby-10.2.1.6.csv Backward4 Logistic Regression {'solver': 'sag', 'penalty': 'l2', 'max_iter': 1500, 'C': 1}\n",
      "hbase-0.95.0.csv Backward2 65 [18 20 36 40 43 55]\n",
      "hbase-0.95.0.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 3000, 'C': 100}\n",
      "hbase-0.95.0.csv Backward3 65 [18 20 21 36 40 43 54 55]\n",
      "hbase-0.95.0.csv Backward3 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 1500, 'C': 1}\n",
      "hbase-0.95.0.csv Backward4 65 [18 20 21 27 29 36 40 43 54 55]\n",
      "hbase-0.95.0.csv Backward4 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 3000, 'C': 10}\n",
      "hive-0.10.0.csv Backward2 65 [ 1 14 22 51 55 59]\n",
      "hive-0.10.0.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 3000, 'C': 1000}\n",
      "hive-0.10.0.csv Backward3 65 [ 1 14 22 29 51 55 59 62]\n",
      "hive-0.10.0.csv Backward3 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 1500, 'C': 100}\n",
      "hive-0.10.0.csv Backward4 65 [ 1 14 22 29 38 44 51 55 59 62]\n",
      "hive-0.10.0.csv Backward4 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.1}\n",
      "camel-2.9.0.csv Backward2 65 [ 0  4 35 51 63 64]\n",
      "camel-2.9.0.csv Backward2 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 100, 'C': 100}\n",
      "camel-2.9.0.csv Backward3 65 [ 0  4 32 35 50 51 63 64]\n",
      "camel-2.9.0.csv Backward3 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.1}\n",
      "camel-2.9.0.csv Backward4 65 [ 0  3  4 32 35 39 50 51 63 64]\n",
      "camel-2.9.0.csv Backward4 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 1500, 'C': 1000}\n",
      "camel-1.4.0.csv Backward2 65 [ 9 29 34 50 55 63]\n",
      "camel-1.4.0.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 3000, 'C': 1000}\n",
      "camel-1.4.0.csv Backward3 65 [ 9 18 29 34 50 55 63 64]\n",
      "camel-1.4.0.csv Backward3 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 3000, 'C': 100}\n",
      "camel-1.4.0.csv Backward4 65 [ 3  9 18 21 29 34 50 55 63 64]\n",
      "camel-1.4.0.csv Backward4 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 1000}\n",
      "activemq-5.1.0.csv Backward2 65 [ 1  9 24 29 55 59]\n",
      "activemq-5.1.0.csv Backward2 Logistic Regression {'solver': 'sag', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.01}\n",
      "activemq-5.1.0.csv Backward3 65 [ 1  9 24 29 32 55 57 59]\n",
      "activemq-5.1.0.csv Backward3 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 1500, 'C': 100}\n",
      "activemq-5.1.0.csv Backward4 65 [ 1  3  9 21 24 29 32 55 57 59]\n",
      "activemq-5.1.0.csv Backward4 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 1500, 'C': 1}\n",
      "jruby-1.7.0.preview1.csv Backward2 65 [ 0  9 10 19 50 51]\n",
      "jruby-1.7.0.preview1.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.0001}\n",
      "jruby-1.7.0.preview1.csv Backward3 65 [ 0  3  9 10 19 29 50 51]\n",
      "jruby-1.7.0.preview1.csv Backward3 Logistic Regression {'solver': 'saga', 'penalty': 'l2', 'max_iter': 3000, 'C': 1}\n",
      "jruby-1.7.0.preview1.csv Backward4 65 [ 0  1  3  9 10 19 29 32 50 51]\n",
      "jruby-1.7.0.preview1.csv Backward4 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.1}\n",
      "wicket-1.3.0-incubating-beta-1.csv Backward2 65 [21 22 31 44 55 60]\n",
      "wicket-1.3.0-incubating-beta-1.csv Backward2 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 1500, 'C': 1000}\n",
      "wicket-1.3.0-incubating-beta-1.csv Backward3 65 [10 21 22 31 44 51 55 60]\n",
      "wicket-1.3.0-incubating-beta-1.csv Backward3 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 1500, 'C': 1}\n",
      "wicket-1.3.0-incubating-beta-1.csv Backward4 65 [10 15 20 21 22 31 44 51 55 60]\n",
      "wicket-1.3.0-incubating-beta-1.csv Backward4 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 1500, 'C': 1}\n",
      "hbase-0.95.2.csv Backward2 65 [14 29 37 43 45 64]\n",
      "hbase-0.95.2.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 1500, 'C': 100}\n",
      "hbase-0.95.2.csv Backward3 65 [14 29 37 42 43 45 60 64]\n",
      "hbase-0.95.2.csv Backward3 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 3000, 'C': 10}\n",
      "hbase-0.95.2.csv Backward4 65 [14 17 29 30 37 42 43 45 60 64]\n",
      "hbase-0.95.2.csv Backward4 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 100, 'C': 0.1}\n",
      "activemq-5.0.0.csv Backward2 65 [11 18 28 30 56 59]\n",
      "activemq-5.0.0.csv Backward2 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 100, 'C': 0.1}\n",
      "activemq-5.0.0.csv Backward3 65 [11 18 23 28 30 56 59 60]\n",
      "activemq-5.0.0.csv Backward3 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 3000, 'C': 100}\n",
      "activemq-5.0.0.csv Backward4 65 [11 18 23 28 30 38 43 56 59 60]\n",
      "activemq-5.0.0.csv Backward4 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 1500, 'C': 1000}\n",
      "activemq-5.8.0.csv Backward2 65 [ 3 16 21 52 55 62]\n",
      "activemq-5.8.0.csv Backward2 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 3000, 'C': 100}\n",
      "activemq-5.8.0.csv Backward3 65 [ 3 16 21 52 55 60 62 63]\n",
      "activemq-5.8.0.csv Backward3 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 3000, 'C': 100}\n",
      "activemq-5.8.0.csv Backward4 65 [ 3  8 16 19 21 52 55 60 62 63]\n",
      "activemq-5.8.0.csv Backward4 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.1}\n",
      "wicket-1.3.0-beta2.csv Backward2 65 [ 1 23 28 29 45 55]\n",
      "wicket-1.3.0-beta2.csv Backward2 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.1}\n",
      "wicket-1.3.0-beta2.csv Backward3 65 [ 1 23 28 29 32 45 50 55]\n",
      "wicket-1.3.0-beta2.csv Backward3 Logistic Regression {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 100, 'C': 0.1}\n",
      "wicket-1.3.0-beta2.csv Backward4 65 [ 1  5 18 23 28 29 32 45 50 55]\n",
      "wicket-1.3.0-beta2.csv Backward4 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 100, 'C': 0.1}\n",
      "lucene-3.1.csv Backward2 65 [ 7 16 17 42 46 57]\n",
      "lucene-3.1.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 3000, 'C': 0.1}\n",
      "lucene-3.1.csv Backward3 65 [ 7 16 17 22 42 46 57 59]\n",
      "lucene-3.1.csv Backward3 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 3000, 'C': 1}\n",
      "lucene-3.1.csv Backward4 65 [ 7 16 17 22 35 42 46 50 57 59]\n",
      "lucene-3.1.csv Backward4 Logistic Regression {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 3000, 'C': 0.1}\n",
      "wicket-1.5.3.csv Backward2 65 [ 3 22 26 27 40 55]\n",
      "wicket-1.5.3.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 3000, 'C': 1}\n",
      "wicket-1.5.3.csv Backward3 65 [ 3 16 22 26 27 40 54 55]\n",
      "wicket-1.5.3.csv Backward3 Logistic Regression {'solver': 'newton-cholesky', 'penalty': 'l2', 'max_iter': 100, 'C': 1000}\n",
      "wicket-1.5.3.csv Backward4 65 [ 1  3 16 22 26 27 40 46 54 55]\n",
      "wicket-1.5.3.csv Backward4 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 1500, 'C': 100}\n",
      "----------------------------------  ---------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "dataset                             feat_algo  acc       prec      recall    f1        mcc       roc_auc   g-m       bal\n",
      "camel-2.11.0.csv                    Backward2  0.83      0.54      0.76      0.53      0.2       0.76      0.79      0.79\n",
      "camel-2.11.0.csv                    Backward3  0.84      0.54      0.76      0.53      0.2       0.76      0.8       0.79\n",
      "camel-2.11.0.csv                    Backward4  0.83      0.54      0.76      0.53      0.2       0.76      0.8       0.79\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "derby-10.5.1.1.csv                  Backward2  0.79      0.63      0.66      0.63      0.29      0.66      0.74      0.73\n",
      "derby-10.5.1.1.csv                  Backward3  0.72      0.61      0.7       0.62      0.3       0.7       0.72      0.72\n",
      "derby-10.5.1.1.csv                  Backward4  0.73      0.61      0.69      0.61      0.29      0.69      0.71      0.71\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "activemq-5.3.0.csv                  Backward2  0.79      0.64      0.77      0.66      0.39      0.77      0.79      0.79\n",
      "activemq-5.3.0.csv                  Backward3  0.8       0.64      0.78      0.66      0.4       0.78      0.79      0.79\n",
      "activemq-5.3.0.csv                  Backward4  0.8       0.64      0.77      0.66      0.4       0.77      0.79      0.79\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "derby-10.3.1.4.csv                  Backward2  0.3       0.15      0.5       0.23      0.0       0.5       0.0       0.21\n",
      "derby-10.3.1.4.csv                  Backward3  0.31      0.6       0.51      0.25      0.06      0.51      0.03      0.22\n",
      "derby-10.3.1.4.csv                  Backward4  0.3       0.25      0.5       0.23      0.01      0.5       0.0       0.21\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "activemq-5.2.0.csv                  Backward2  0.89      0.73      0.8       0.75      0.52      0.8       0.85      0.84\n",
      "activemq-5.2.0.csv                  Backward3  0.89      0.72      0.8       0.75      0.52      0.8       0.85      0.84\n",
      "activemq-5.2.0.csv                  Backward4  0.83      0.66      0.77      0.68      0.41      0.77      0.81      0.8\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "hive-0.12.0.csv                     Backward2  0.76      0.6       0.76      0.6       0.31      0.76      0.76      0.76\n",
      "hive-0.12.0.csv                     Backward3  0.21      0.54      0.56      0.2       0.09      0.56      0.21      0.32\n",
      "hive-0.12.0.csv                     Backward4  0.76      0.6       0.77      0.6       0.33      0.77      0.76      0.76\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "camel-2.10.0.csv                    Backward2  0.86      0.56      0.78      0.57      0.26      0.78      0.82      0.82\n",
      "camel-2.10.0.csv                    Backward3  0.86      0.56      0.78      0.57      0.26      0.78      0.82      0.82\n",
      "camel-2.10.0.csv                    Backward4  0.85      0.56      0.79      0.57      0.26      0.79      0.82      0.82\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "derby-10.2.1.6.csv                  Backward2  0.81      0.79      0.79      0.79      0.58      0.79      0.82      0.82\n",
      "derby-10.2.1.6.csv                  Backward3  0.82      0.8       0.79      0.79      0.59      0.79      0.83      0.82\n",
      "derby-10.2.1.6.csv                  Backward4  0.79      0.77      0.79      0.77      0.55      0.79      0.79      0.79\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "hbase-0.95.0.csv                    Backward2  0.74      0.65      0.67      0.66      0.32      0.67      0.73      0.73\n",
      "hbase-0.95.0.csv                    Backward3  0.74      0.66      0.67      0.66      0.33      0.67      0.73      0.73\n",
      "hbase-0.95.0.csv                    Backward4  0.74      0.65      0.67      0.66      0.32      0.67      0.73      0.73\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "hive-0.10.0.csv                     Backward2  0.82      0.66      0.78      0.69      0.42      0.78      0.81      0.8\n",
      "hive-0.10.0.csv                     Backward3  0.82      0.66      0.78      0.68      0.42      0.78      0.8       0.8\n",
      "hive-0.10.0.csv                     Backward4  0.82      0.66      0.77      0.68      0.41      0.77      0.8       0.8\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "camel-2.9.0.csv                     Backward2  0.83      0.55      0.77      0.54      0.23      0.77      0.8       0.8\n",
      "camel-2.9.0.csv                     Backward3  0.83      0.55      0.78      0.55      0.24      0.78      0.81      0.81\n",
      "camel-2.9.0.csv                     Backward4  0.83      0.55      0.78      0.55      0.24      0.78      0.81      0.81\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "camel-1.4.0.csv                     Backward2  0.74      0.65      0.72      0.66      0.37      0.72      0.73      0.73\n",
      "camel-1.4.0.csv                     Backward3  0.74      0.66      0.73      0.66      0.37      0.73      0.73      0.73\n",
      "camel-1.4.0.csv                     Backward4  0.73      0.66      0.73      0.66      0.38      0.73      0.73      0.73\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "activemq-5.1.0.csv                  Backward2  0.8       0.61      0.77      0.62      0.34      0.77      0.79      0.79\n",
      "activemq-5.1.0.csv                  Backward3  0.76      0.6       0.76      0.6       0.32      0.76      0.76      0.76\n",
      "activemq-5.1.0.csv                  Backward4  0.77      0.59      0.75      0.6       0.31      0.75      0.76      0.76\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "jruby-1.7.0.preview1.csv            Backward2  0.57      0.54      0.7       0.44      0.19      0.7       0.62      0.62\n",
      "jruby-1.7.0.preview1.csv            Backward3  0.81      0.59      0.77      0.6       0.31      0.77      0.79      0.79\n",
      "jruby-1.7.0.preview1.csv            Backward4  0.82      0.59      0.77      0.6       0.3       0.77      0.79      0.79\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "wicket-1.3.0-incubating-beta-1.csv  Backward2  0.86      0.63      0.83      0.66      0.41      0.83      0.84      0.84\n",
      "wicket-1.3.0-incubating-beta-1.csv  Backward3  0.86      0.62      0.82      0.66      0.4       0.82      0.84      0.83\n",
      "wicket-1.3.0-incubating-beta-1.csv  Backward4  0.86      0.63      0.81      0.66      0.4       0.81      0.84      0.83\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "hbase-0.95.2.csv                    Backward2  0.72      0.66      0.69      0.67      0.35      0.69      0.72      0.72\n",
      "hbase-0.95.2.csv                    Backward3  0.71      0.66      0.68      0.66      0.34      0.68      0.71      0.71\n",
      "hbase-0.95.2.csv                    Backward4  0.71      0.66      0.69      0.66      0.34      0.69      0.71      0.71\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "activemq-5.0.0.csv                  Backward2  0.85      0.73      0.81      0.76      0.54      0.81      0.84      0.84\n",
      "activemq-5.0.0.csv                  Backward3  0.85      0.74      0.81      0.76      0.54      0.81      0.84      0.84\n",
      "activemq-5.0.0.csv                  Backward4  0.85      0.74      0.82      0.76      0.55      0.82      0.84      0.84\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "activemq-5.8.0.csv                  Backward2  0.8       0.59      0.77      0.6       0.31      0.77      0.79      0.79\n",
      "activemq-5.8.0.csv                  Backward3  0.8       0.59      0.77      0.6       0.31      0.77      0.79      0.79\n",
      "activemq-5.8.0.csv                  Backward4  0.8       0.59      0.77      0.6       0.31      0.77      0.79      0.79\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "wicket-1.3.0-beta2.csv              Backward2  0.78      0.6       0.77      0.6       0.32      0.77      0.77      0.77\n",
      "wicket-1.3.0-beta2.csv              Backward3  0.79      0.6       0.78      0.61      0.34      0.78      0.79      0.79\n",
      "wicket-1.3.0-beta2.csv              Backward4  0.79      0.6       0.77      0.61      0.32      0.77      0.78      0.78\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "lucene-3.1.csv                      Backward2  0.76      0.54      0.73      0.52      0.2       0.73      0.75      0.74\n",
      "lucene-3.1.csv                      Backward3  0.77      0.54      0.72      0.52      0.19      0.72      0.74      0.74\n",
      "lucene-3.1.csv                      Backward4  0.68      0.54      0.72      0.47      0.17      0.72      0.69      0.69\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "wicket-1.5.3.csv                    Backward2  0.81      0.56      0.74      0.56      0.24      0.74      0.78      0.77\n",
      "wicket-1.5.3.csv                    Backward3  0.81      0.56      0.76      0.56      0.25      0.76      0.78      0.78\n",
      "wicket-1.5.3.csv                    Backward4  0.81      0.56      0.76      0.56      0.26      0.76      0.78      0.78\n",
      "--------                            --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "----------------------------------  ---------  --------  --------  --------  --------  --------  --------  --------  --------\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/kaggle/input/defect-prediction/JIRA-defect-dataset'\n",
    "files_list = get_list_of_csv(folder_path)\n",
    "\n",
    "for model in models_list.keys():\n",
    "    print('----------------',model,'---------------------------')\n",
    "    table = []\n",
    "    table.append([\"dataset\", \"feat_algo\", \"acc\", \"prec\", \"recall\", \"f1\", \"mcc\", \"roc_auc\", \"g-m\", \"bal\"])\n",
    "    for file_name in files_list:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if df.shape[0]<=1500:\n",
    "            continue\n",
    "        \n",
    "        df = process_jira_dataset(df)\n",
    "        X = df.drop(columns=[df.columns[-1]]).values\n",
    "        y = df[df.columns[-1]].values\n",
    "        \n",
    "#         table.append(build_model(file_name, X, y, model, 'None'))\n",
    "        for feat_algo in feature_algo.keys():\n",
    "            table.append(build_model(file_name, X, y, model, feat_algo))\n",
    "        table.append(['--------', '--------', '--------', '--------', '--------', '--------', '--------', '--------', '--------', '--------'])\n",
    "    print(tabulate(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70027fca",
   "metadata": {
    "papermill": {
     "duration": 0.014918,
     "end_time": "2023-10-31T07:25:18.745027",
     "exception": false,
     "start_time": "2023-10-31T07:25:18.730109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### AEEEM Defect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "310752f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T07:25:18.776300Z",
     "iopub.status.busy": "2023-10-31T07:25:18.775425Z",
     "iopub.status.idle": "2023-10-31T07:26:23.446138Z",
     "shell.execute_reply": "2023-10-31T07:26:23.445275Z"
    },
    "papermill": {
     "duration": 64.688704,
     "end_time": "2023-10-31T07:26:23.448501",
     "exception": false,
     "start_time": "2023-10-31T07:25:18.759797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Logistic Regression ---------------------------\n",
      "mylyn.csv Backward2 15 [ 0  4  6 11 13 14]\n",
      "mylyn.csv Backward2 Logistic Regression {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 3000, 'C': 100}\n",
      "mylyn.csv Backward3 15 [ 0  2  4  6  9 11 13 14]\n",
      "mylyn.csv Backward3 Logistic Regression {'solver': 'sag', 'penalty': 'l2', 'max_iter': 3000, 'C': 100}\n",
      "mylyn.csv Backward4 15 [ 0  2  4  6  9 10 11 12 13 14]\n",
      "mylyn.csv Backward4 Logistic Regression {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 1500, 'C': 0.001}\n",
      "---------  ---------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "dataset    feat_algo  acc       prec      recall    f1        mcc       roc_auc   g-m       bal\n",
      "mylyn.csv  Backward2  0.68      0.61      0.73      0.59      0.32      0.73      0.69      0.69\n",
      "mylyn.csv  Backward3  0.79      0.62      0.68      0.63      0.29      0.68      0.74      0.74\n",
      "mylyn.csv  Backward4  0.75      0.61      0.7       0.62      0.31      0.7       0.73      0.73\n",
      "--------   --------   --------  --------  --------  --------  --------  --------  --------  --------\n",
      "---------  ---------  --------  --------  --------  --------  --------  --------  --------  --------\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/kaggle/input/defect-prediction/AEEEM-defect-dataset'\n",
    "files_list = get_list_of_csv(folder_path)\n",
    "\n",
    "for model in models_list.keys():\n",
    "    print('----------------',model,'---------------------------')\n",
    "    table = []\n",
    "    table.append([\"dataset\", \"feat_algo\", \"acc\", \"prec\", \"recall\", \"f1\", \"mcc\", \"roc_auc\", \"g-m\", \"bal\"])\n",
    "    for file_name in files_list:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path, delimiter=';')\n",
    "        \n",
    "        if df.shape[0]<=1500:\n",
    "            continue\n",
    "            \n",
    "        df = process_aeeem_dataset(df)\n",
    "        X = df.drop(columns=[df.columns[-1]]).values\n",
    "        y = df[df.columns[-1]].values\n",
    "        \n",
    "#         table.append(build_model(file_name, X, y, model, 'None'))\n",
    "        for feat_algo in feature_algo.keys():\n",
    "            table.append(build_model(file_name, X, y, model, feat_algo))\n",
    "        table.append(['--------', '--------', '--------', '--------', '--------', '--------', '--------', '--------', '--------', '--------'])\n",
    "    print(tabulate(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145c311",
   "metadata": {
    "papermill": {
     "duration": 0.01554,
     "end_time": "2023-10-31T07:26:23.480065",
     "exception": false,
     "start_time": "2023-10-31T07:26:23.464525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24214.329399,
   "end_time": "2023-10-31T07:26:24.250178",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-31T00:42:49.920779",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
